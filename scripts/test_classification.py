#!/usr/bin/env python3
"""
æµ‹è¯•å¤šæ¨¡æ€åˆ†ç±»åŠŸèƒ½
"""

import torch
import dgl
import numpy as np
from config.model_config import ModelConfig
from src.models.downstream import (
    create_classification_model,
    create_classification_loss,
    create_classification_pipeline,
    ClassificationMetrics,
    CAD_PART_CLASSES
)


def test_classification_model():
    """æµ‹è¯•åˆ†ç±»æ¨¡å‹"""
    print("Testing Classification Model...")

    try:
        config = ModelConfig()
        classifier = create_classification_model(config)
        criterion = create_classification_loss(config)

        batch_size = 4

        # æ¨¡æ‹Ÿèåˆç‰¹å¾è¾“å…¥
        fusion_output = {
            'fused_features': torch.randn(batch_size, config.fusion_dim),
            'image_enhanced': torch.randn(batch_size, config.fusion_dim),
            'brep_enhanced': torch.randn(batch_size, config.fusion_dim)
        }

        # æ¨¡æ‹Ÿæ ‡ç­¾
        targets = torch.randint(0, config.num_classes, (batch_size,))

        with torch.no_grad():
            # æµ‹è¯•å‰å‘ä¼ æ’­
            outputs = classifier(fusion_output)
            losses = criterion(outputs, targets)

            print(f"  âœ“ ä¸»åˆ†ç±»å™¨è¾“å‡ºå½¢çŠ¶: {outputs['logits'].shape}")
            print(f"  âœ“ æ¦‚ç‡è¾“å‡ºå½¢çŠ¶: {outputs['probabilities'].shape}")
            print(f"  âœ“ ç‰¹å¾é‡è¦æ€§å½¢çŠ¶: {outputs['feature_importance'].shape}")
            print(f"  âœ“ æ€»æŸå¤±: {losses['total_loss'].item():.4f}")

            # æµ‹è¯•é¢„æµ‹åŠŸèƒ½
            predictions = classifier.predict(fusion_output)
            print(f"  âœ“ é¢„æµ‹ç»“æœ: {predictions['predictions']}")
            print(f"  âœ“ ç½®ä¿¡åº¦: {predictions['confidence']}")

            # éªŒè¯è¾“å‡ºç»´åº¦
            assert outputs['logits'].shape == (batch_size, config.num_classes)
            assert outputs['probabilities'].shape == (batch_size, config.num_classes)
            assert outputs['feature_importance'].shape == (batch_size, 1)

        print("  âœ“ Classification model test passed!")
        return True

    except Exception as e:
        print(f"  âœ— Classification model test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_classification_metrics():
    """æµ‹è¯•åˆ†ç±»æŒ‡æ ‡"""
    print("Testing Classification Metrics...")

    try:
        config = ModelConfig()
        metrics = ClassificationMetrics(config.num_classes)

        # æ¨¡æ‹Ÿé¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
        batch_size = 20
        predictions = torch.randint(0, config.num_classes, (batch_size,))
        targets = torch.randint(0, config.num_classes, (batch_size,))

        # æ›´æ–°æŒ‡æ ‡
        metrics.update(predictions, targets)

        # è®¡ç®—æŒ‡æ ‡
        results = metrics.compute()

        print(f"  âœ“ æ•´ä½“å‡†ç¡®ç‡: {results['accuracy']:.4f}")
        print(f"  âœ“ å¹³å‡å‡†ç¡®ç‡: {results['mean_accuracy']:.4f}")
        print(f"  âœ“ æ¯ç±»å‡†ç¡®ç‡æ•°é‡: {len(results['class_accuracies'])}")

        # éªŒè¯æŒ‡æ ‡èŒƒå›´
        assert 0 <= results['accuracy'] <= 1
        assert 0 <= results['mean_accuracy'] <= 1
        assert len(results['class_accuracies']) == config.num_classes

        print("  âœ“ Classification metrics test passed!")
        return True

    except Exception as e:
        print(f"  âœ— Classification metrics test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_classification_pipeline():
    """æµ‹è¯•å®Œæ•´åˆ†ç±»ç®¡é“"""
    print("Testing Classification Pipeline...")

    try:
        config = ModelConfig()
        pipeline = create_classification_pipeline(config)

        batch_size = 2

        # å‡†å¤‡å›¾åƒæ•°æ®
        images = torch.randn(batch_size, 3, 3, 224, 224)

        # å‡†å¤‡Brepæ•°æ®
        graphs = []
        for _ in range(batch_size):
            num_nodes = 6
            src = torch.tensor([0, 1, 2, 3, 4, 5, 0, 1, 2])
            dst = torch.tensor([1, 2, 3, 4, 5, 0, 2, 3, 4])
            graph = dgl.graph((src, dst), num_nodes=num_nodes)
            graph = dgl.add_self_loop(graph)
            graph.ndata['x'] = torch.randn(num_nodes, 7)
            graphs.append(graph)

        batched_graphs = dgl.batch(graphs)
        labels = torch.randint(0, config.num_classes, (batch_size,))

        with torch.no_grad():
            # æµ‹è¯•è®­ç»ƒæ¨¡å¼
            results = pipeline(images, batched_graphs, labels)

            print(f"  âœ“ é¢„æµ‹ç»“æœå½¢çŠ¶: {results['predictions'].shape}")
            print(f"  âœ“ æ¦‚ç‡è¾“å‡ºå½¢çŠ¶: {results['probabilities'].shape}")
            print(f"  âœ“ æ€»æŸå¤±: {results['total_loss'].item():.4f}")
            print(f"  âœ“ ä¸»æŸå¤±: {results['main_loss'].item():.4f}")

            # æµ‹è¯•æ¨ç†æ¨¡å¼
            pred_results = pipeline.predict(images, batched_graphs)
            print(f"  âœ“ æ¨ç†é¢„æµ‹: {pred_results['predictions']}")
            print(f"  âœ“ ç½®ä¿¡åº¦èŒƒå›´: [{pred_results['confidence'].min().item():.4f}, {pred_results['confidence'].max().item():.4f}]")

            # æµ‹è¯•ç‰¹å¾æå–
            features = pipeline.extract_features(images, batched_graphs)
            print(f"  âœ“ å›¾åƒç‰¹å¾å½¢çŠ¶: {features['image_features'].shape}")
            print(f"  âœ“ Brepç‰¹å¾å½¢çŠ¶: {features['brep_features'].shape}")
            print(f"  âœ“ èåˆç‰¹å¾å½¢çŠ¶: {features['fused_features'].shape}")

            # éªŒè¯è¾“å‡ºç»´åº¦
            assert results['predictions'].shape == (batch_size,)
            assert results['probabilities'].shape == (batch_size, config.num_classes)
            assert features['fused_features'].shape == (batch_size, config.fusion_dim)

        print("  âœ“ Classification pipeline test passed!")
        return True

    except Exception as e:
        print(f"  âœ— Classification pipeline test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_cad_part_classes():
    """æµ‹è¯•CADé›¶ä»¶ç±»åˆ«å®šä¹‰"""
    print("Testing CAD Part Classes...")

    try:
        print(f"  âœ“ å®šä¹‰çš„CADé›¶ä»¶ç±»åˆ«æ•°é‡: {len(CAD_PART_CLASSES)}")
        print(f"  âœ“ ç±»åˆ«åˆ—è¡¨: {CAD_PART_CLASSES}")

        # éªŒè¯ç±»åˆ«æ•°é‡ä¸é…ç½®ä¸€è‡´
        config = ModelConfig()
        assert len(CAD_PART_CLASSES) == config.num_classes, f"ç±»åˆ«æ•°é‡ä¸åŒ¹é…: {len(CAD_PART_CLASSES)} != {config.num_classes}"

        print("  âœ“ CAD part classes test passed!")
        return True

    except Exception as e:
        print(f"  âœ— CAD part classes test failed: {e}")
        return False


def test_end_to_end_classification():
    """ç«¯åˆ°ç«¯åˆ†ç±»æµ‹è¯•"""
    print("Testing End-to-End Classification...")

    try:
        config = ModelConfig()
        pipeline = create_classification_pipeline(config)

        batch_size = 3

        # åˆ›å»ºæ›´çœŸå®çš„æµ‹è¯•æ•°æ®
        images = torch.randn(batch_size, 3, 3, 224, 224)

        # åˆ›å»ºä¸åŒå¤§å°çš„å›¾
        graphs = []
        expected_predictions = []

        for i in range(batch_size):
            # ä¸åŒçš„å›¾å¤§å°
            num_nodes = 4 + i * 2

            # åˆ›å»ºè¿é€šå›¾
            edges = []
            for j in range(num_nodes):
                edges.append((j, (j + 1) % num_nodes))  # ç¯å½¢è¿æ¥

            if num_nodes > 3:  # æ·»åŠ é¢å¤–è¿æ¥
                edges.append((0, num_nodes // 2))
                edges.append((1, num_nodes - 1))

            src, dst = zip(*edges)
            graph = dgl.graph((torch.tensor(src), torch.tensor(dst)), num_nodes=num_nodes)
            graph = dgl.add_self_loop(graph)

            # ä¸åŒçš„ç‰¹å¾æ¨¡å¼
            if i == 0:  # ç®€å•ç‰¹å¾
                graph.ndata['x'] = torch.ones(num_nodes, 7) * 0.5
            elif i == 1:  # éšæœºç‰¹å¾
                graph.ndata['x'] = torch.randn(num_nodes, 7)
            else:  # ç»“æ„åŒ–ç‰¹å¾
                features = torch.zeros(num_nodes, 7)
                features[:, i % 7] = 1.0  # one-hot like
                graph.ndata['x'] = features

            graphs.append(graph)

        batched_graphs = dgl.batch(graphs)

        with torch.no_grad():
            # æ¨ç†æµ‹è¯•
            results = pipeline.predict(images, batched_graphs)

            print(f"  âœ“ æ‰¹é‡é¢„æµ‹ç»“æœ: {results['predictions']}")
            print(f"  âœ“ å¹³å‡ç½®ä¿¡åº¦: {results['confidence'].mean().item():.4f}")
            print(f"  âœ“ ç‰¹å¾é‡è¦æ€§å‡å€¼: {results['feature_importance'].mean().item():.4f}")

            # å•ç‹¬é¢„æµ‹æ¯ä¸ªæ ·æœ¬
            for i in range(batch_size):
                single_image = images[i:i+1]
                single_graph = dgl.unbatch(batched_graphs)[i]
                single_batched = dgl.batch([single_graph])

                single_result = pipeline.predict(single_image, single_batched)
                print(f"  âœ“ æ ·æœ¬ {i+1} é¢„æµ‹: ç±»åˆ« {single_result['predictions'].item()}, ç½®ä¿¡åº¦ {single_result['confidence'].item():.4f}")

        print("  âœ“ End-to-end classification test passed!")
        return True

    except Exception as e:
        print(f"  âœ— End-to-end classification test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("TESTING MULTIMODAL CLASSIFICATION")
    print("=" * 60)

    tests = [
        ("Classification Model", test_classification_model),
        ("Classification Metrics", test_classification_metrics),
        ("Classification Pipeline", test_classification_pipeline),
        ("CAD Part Classes", test_cad_part_classes),
        ("End-to-End Classification", test_end_to_end_classification)
    ]

    results = []
    for test_name, test_func in tests:
        print(f"\n{test_name}:")
        print("-" * 40)
        success = test_func()
        results.append((test_name, success))
        print()

    # æ€»ç»“
    print("=" * 60)
    print("CLASSIFICATION TEST SUMMARY")
    print("=" * 60)

    all_passed = True
    for test_name, success in results:
        status = "âœ“ PASSED" if success else "âœ— FAILED"
        print(f"{test_name:<30} {status}")
        if not success:
            all_passed = False

    print("-" * 60)
    if all_passed:
        print("ğŸ‰ ALL CLASSIFICATION TESTS PASSED!")
        print("The multimodal classification system is working correctly.")
        print(f"âœ“ Support for {len(CAD_PART_CLASSES)} CAD part classes")
        print("âœ“ End-to-end pipeline ready for training")
    else:
        print("âŒ Some classification tests failed. Please check the error messages above.")

    return all_passed


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)